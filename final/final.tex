\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
% \usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{geometry}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{titling}

\title{Jersey Number Recognition}
% \subtitle{CS 221 Final Project, Fall 2014}
\author{Roger Chen and Audrey Ho and Jenny Hong}

\date{\today}

\begin{document}
\maketitle

\section{Introduction}

Roger has work to do for the Stanford Daily but he doesn't really want to do it. \\

The goal of this project is to evaluate various artificial intelligence techniques in the application of computer vision. Specifically, we want to read numbers from photos of Stanford football players' jerseys. This involves acquiring or generating data, and digit classification. This is the primary artificial intelligence problem described in the paper.

\subsection{Problem Definition}

Our problem is to create a system which takes as input images and outputs a classification as a digit 0-9. This task is similar to handwritten OCR tasks, but adds additional challenges of dimensionality as well as locating the digits in a noisy image in the first place. Given this problem definition, we naturally looked to applying heuristics to image processing in tandem with supervised learning algorithms.

\subsection{Challenges}

We did not focus on using top-of-line computer vision techniques, and as a result we simplified the problem inputs to images from the Stanford Daily of Stanford football players wearing our home jerseys (red uniforms with white lettering). 

\section{Data}

We get our data from Roger Chen.

{\bf Image processing.} The goal of image processing is to segment numbers from images. We begin by increasing the contrast through RGB and HSV histogram manipulation to normalize across different lighting and texture conditions. Next, we identify separately the red blobs and white blobs in the photo, filtering based on HSV thresholds. Because we only are concerned with blobs of a certain size, we ignore all specks and small disks as noise. Finally, we apply the heuristic that white numbers are only surrounded by red, and isolate those blobs. \\

{\bf Data generation.} Base images for the training data are created as black and white bitmaps from the numbers 0-9 in College font. This is accomplished with the Python Image Library (PIL). They are then transformed through a variety of skews and transforms to simulate the potential positions that a digit could be in while on a player's back. \\

\section{Model Overview}

Our pipeline has two stages

1. Image segmentation
2. Digit classification

\section{Image Segmentation}

Audrey is super cool and did image magicks.

\section{Classification}

In this section, we describe the approaches we took to our supervised learning problem.

\subsection{Baseline: $k$-nearest neighbors}

We used the $k$-nearest neighbors algorithm as a baseline. Our data were the raw images, so the $k$-nearest neighbors algorithm measured similarity in the $100 \times 100$ image space.

\subsection{Random Forest}

The random forest classification algorithm makes use of multiple trees from decision tree learning. Each tree is grown over a random subset of the data. An internal node of at ree represents an input feature, and the leaves are labeled with a distribution over the classes. The random forest approach returns the most common classification returned by any of its trees. 

\subsection{Support Vector Machines}

Our main design decisions were made in choosing the feature representation and the kernel. For the feature, we used Histogram of Oriented Gradients (HoG), which has been known to work well in digit recognition. We use the Sobel operator to compute the gradient of the image. We divide the image into four bins and compute the histogram. We experimented with different bin sizes, but since our images were already only 100x100 pixels, four bins seemed to work better than 16, etc. We are currently using the radial basis function $K(x_i, x_j) = \mbox{exp }(-\gamma \|x_i - x_j\|^2)$ for the kernel. We have experimented with polynomial kernels, but limited testing data prevents us from arguing strongly for one kernel over the other.

\section{Results}

We train our classifiers on 69 distinct transformations of each digit, and test on $n=30$ samples. We are able to obtain a 76.78\% accuracy using kNN on raw pixel data, a 50.00\% accuracy using SVMs with the HoG feature, and a 33.33\% accuracy with random forests and the HoG feature.

\section{Analysis}

We were surprised at how simple heuristics can go a long way in addressing OCR issues. kNN represented a rather naive way of looking at the problem space, but also turned out to be the most effective. In additon, we found that normalizing the test data to be of a consistent size and position had an enormous impact on the classifiers and their ability to perform. \\ 

We find that digits can be reliably isolated from an arbitrary image through heuristic-based image processing. We also find that synthetic training data generated from a base font and skewed across a variety of transforms is appropriate as a training corpus for this jersey ORC task. When these two processes are chained together, we are able to identify players that are represented in a photo. 

\section{Future Work}

% \bibliography

\end{document}